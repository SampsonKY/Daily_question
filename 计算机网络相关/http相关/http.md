## HTTP历史

> 时势造英雄，英雄亦造实事。

### 史前时期

20世纪60年代，美国国防部高等研究计划部署（ARPA）建立了 ARPA 网，它有四个分布在各地的结点，被认为是如今互联网的”始祖“。

然后在 70 年代，基于对 ARPA 网的实践和思考，研究人员发明出了著名的 TCP/IP 协议。由于具有良好的分层结构和稳定的性能，TCP/IP 协议迅速战胜其他竞争对手流行起来，并在 80 年代中期进入了 UNIX 系统内核，促使更多的计算机接入。

### 创世纪

1989 年，任职于欧洲核子研究中心（CERN）的蒂姆·伯纳斯 - 李（Tim Berners-Lee）提出了在互联网上构建超链接文档系统的构想。这篇论文中他确立了三项关键技术。

1. URI：即统一资源标识符，作为互联网上资源的唯一身份；

2. HTML：即超文本标记语言，描述超文本文档；

3. HTTP：即超文本传输协议，用来传输超

基于它们，就可以把超文本系统完美地运行在互联网上，让各地的人们能够自由地共享信息，蒂姆把这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web。

所以在这一年，HTTP 诞生了。

### HTTP/0.9

- 这个时代，计算机处理能力低，存储容量小，网速慢。网络上绝大多数资源是纯文本，很多通信协议也都使用纯文本。
- 受时代限制，这个时期的HTTP结构简单，为了便于服务器和客户端处理，采用了纯文本格式。只允许“GET”从服务器获取HTML文档，且在响应请求后立即关闭连接，功能有限。
- HTTP/0.9 虽然简单，但其作为一个原型，充分验证了Web服务器的可行性。

### HTTP/1.0

93 年，NCSA（美国国家超级计算应用中心）开发出了 Mosaic，是第一个可以图文混排的浏览器，95 年开发出了服务器软件 Apache，简化了 HTTP 服务器的搭建工作。同一时期，计算机多媒体技术也有了新的发展：1992 年发明了 JPEG 图像格式，1995 年发明了 MP3 音乐格式。这些技术促进了HTTP发展。

1. 增加了 HEAD、POST 等新方法；

2. 增加了响应状态码，标记可能的错误原因；

3. 引入了协议版本号概念；

4. 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活；

5. 传输的数据不再仅限于文本

**但 HTTP/1.0 并不是一个“标准”**。

### HTTP/1.1

1995 年，网景的 Netscape Navigator 和微软的 Internet Explorer 开始了著名的“浏览器大战”，都希望在互联网上占据主导地位。最终IE胜出。“浏览器大战”极大地推进了Web发展，HTTP/1.0 也在这个过程中经受了实践检验。

于是在1999 年，HTTP/1.1 发布了 RFC 文档，编号为 2616，正式确立了延续十余年的传奇。

HTTP/1.1 主要的变更点有：

1. 增加了 PUT、DELETE 等新的方法；

2. 增加了缓存管理和控制；

3. 明确了连接管理，允许持久连接；

4. 允许响应数据分块（chunked），利于传输大文件；

5. 强制要求 Host 头，让互联网主机托管成为

### HTTP/2

HTTP/1.1 发布之后，整个互联网世界呈现出了爆发式的增长，度过了十多年的“快乐时光”，更涌现出了 Facebook、Twitter、淘宝、京东等互联网新贵。

HTTP/2 的制定充分考虑了现今互联网的现状：宽带、移动、不安全，在高度兼容HTTP/1.1 的同时在性能改善方面做了很大努力，主要的特点有：

1. 二进制协议，不再是纯文本；

2. 可发起多个请求，废弃了 1.1 里的管道；

3. 使用专用算法压缩头部，减少数据传输量；

4. 允许服务器主动向客户端推送数据；

5. 增强了安全性，“事实上”要求加密

### HTTP/3

- 2018年，HTTP/3正式进入标准化制定阶段。

### 小结

1. HTTP 协议始于三十年前蒂姆·伯纳斯 - 李的一篇论文；

2. HTTP/0.9 是个简单的文本协议，只能获取文本资源；

3. HTTP/1.0 确立了大部分现在使用的技术，但它不是正式标准；

4. HTTP/1.1 是目前互联网上使用最广泛的协议，功能也非常完善；

5. HTTP/2 基于 Google 的 SPDY 协议，注重性能改善，但还未普及；

6. HTTP/3 基于 Google 的 QUIC 协议，是将来的发展



## HTTP是什么

> HTTP 就是**超文本传输协议**，即 HyperText Transfer Protocol。

**协议**

- 协议必须有两个或多个参与者，即“协”。
- 协议是对参与者的一种行为约定和规范，即“议”。
- 协议应该包括语法、语义、同步规则和错误处理。
- 第一层含义：HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。

**传输**："A<===>B"

- HTTP是一个“**双向协议**”
- 数据传输过程中可以存在“**中间人**”，即“A<=>X<=>Y<=>B"，这些”中间人“也都遵从HTTP协议，只要不打扰基本数据传输，就可以添加任意的额外功能，如安全验证、数据压缩、编码转换等，优化整个传输过程。
- 第二层含义： HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。 

**超文本**

- 是文字、图片、音频和视频等的混合体，最关键的是含有“超链接”，能够从一个“超文本”跳跃到另一个“超文本”，形成复杂的非线性、网状的结构关系。

有上面三个概念，可以给出更精确的定义：**HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范**。

**HTTP不是什么？**

- HTTP不是互联网。（HTTP是构建互联网的一部分）
- HTTP不是编程语言。
- HTTP不是HTML。
- HTTP不是一个孤立的协议。（HTTP通常跑在TCP/IP协议栈之上）

**HTTP 是构建互联网的重要基础技术，它没有实体，依赖许多其他的技术来实现，但同时许多技术也都依赖于它。**



### 关于域名

### 域名

- 域名是一个有层次的结构，是一串用"."分隔的多个单词，最右边被称为“顶级域名”，然后是“二级域名”，层级关系依次向左依次降低。
- 最左边是主机名，通常用来表明主机用途。如“www"表示提供万维网服务、”mail"表示提供邮件服务。但也并非绝对。

- 域名不仅能代替IP，还有其他用途。比如在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务，比如在 Nginx 里就会使用“server_name”指令：

  ```js
  server{
      listen 80;
      server_name back.sampsonky.top;
      ...
  }
  ```

- 域名本质上还是个名字空间系统，使用多级域名就可以划分出不同的国家、地区、组织、公司、部门，每个域名都是独一无二的，可以作为一种身份的标识。



### 域名的解析

**域名解析**：域名  ---> IP地址。通过DNS完成。

DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：

1. 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址；

2. 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；

3. 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址。

<img src="C:\Users\小新的光屁屁超人\Desktop\KY的HTTP笔记【老婆大人勿删】\images\DNS.png" alt="DNS" style="zoom:80%;" />

任何一个域名都可以在这个树形结构里从顶至下进行查询，就好像是把域名从右到左顺序走了一遍，最终就获得了域名对应的 IP 地址。

**缓存**（一种用来减轻域名解析的压力，并且能够更快地获取结果的手段）

- 首先，许多大公司、网络运行商都会建立自己的 DNS 服务器（非权威域名服务器），作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。这些服务器可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址。这些 DNS 服务器的数量要比核心系统的服务器多很多，而且大多部署在离用户很近的地方。比较知名的 DNS 有 Google 的“8.8.8.8”，Microsoft 的“4.2.2.1”，还有CloudFlare 的“1.1.1.1”等等。

- 其次，**操作系统**也会对 DNS 解析结果进行缓存，如果你之前访问过“www.apple.com”，那么下一次在浏览器里再输入这个网址的时候就不会再跑到DNS 那里去问了，直接在操作系统里就可以拿到 IP 地址。

- 另外，操作系统里还有一个特殊的**“主机映射”文件**，通常是一个可编辑的文本，在 Linux里是“/etc/hosts”，在 Windows 里是“C:\WINDOWS\system32\drivers\etc\hosts”，如果操作系统在缓存里找不到 DNS记录，就会找这个文件。

- 在 Nginx 中有一条配置指令“resolver”，用来配置DNS服务器，如果没有它，那么 Nginx 就无法查询域名对应的 IP，也就无法反向代理到外部的网站。

  ```nginx
  resover 8.8.8.8 valid=30s; #指定Google的DNS，缓存30s
  ```

**负载均衡**

- 因为域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机，客户端收到多个 IP 地址后，就可以自己使用轮询算法依次向服务器发起请求，实现负载均衡。
- 域名解析可以配置内部的策略，返回离客户端最近的主机，或者返回当前服务质量最好的主机，这样在 DNS 端把请求分发到不同的服务器，实现负载均衡。

## HTTP 报文

HTTP协议的请求报文和响应报文结构基本相同，由以下部分组成：

- 起始行（start line）：描述请求或响应的基本信息。
- 头部字段集合（header）：使用 key-value 形式更详细地说明报文。
- 空行：用来区分开头部和实体。
- 消息正文（entity）：实际传输地数据，它不一定是纯文本，可以是图片、视频等二进制数据。

这其中前两部分起始行和头部字段经常又合称为“**请求头**“或”**响应头**“，消息正文又称为”**实体**”（body）。

<img src="images\HTTP报文.png" alt="HTTP报文" style="zoom:50%;" />

例如：

<img src="images\HTTP报文例子.png" alt="HTTP报文例子" style="zoom:50%;" />

**请求行（request line）**：请求报文的起始行

- 简要地描述了客户端想要如何操作服务器端的资源。
- 由三部分构成：
  - 请求方法：是一个动词，如 GET/POST， 表示对资源的操作
  - 请求目标：通常是一个 URI，标记了请求方法要操作的资源
  - 版本号：表示报文使用的HTTP版本协议
- `GET / HTTP/1.1`

**状态行（status line）**：响应报文的起始行

- 服务器相应的状态。
- 三部分构成
  - 版本号：表示报文使用的 HTTP 版本协议
  - **状态码**：三位数，用代码的形式表示处理的结果，比如200是成功，500是服务器错误
  - 原因：座位数字状态码的补充，是更详细的解释文字。

- `HTTP/1.1 200 OK`

在起始行中，每两个部分之间用**空格**隔开，最后一个部分后面应该接一个**换行**，严格遵循`ABNF`语法规范。 

**头部字段**

- key-value 形式
- 字段名不区分大小写
- 字段名不允许出现空格，可以使用‘-’，不可使用‘_'。
- 字段名后紧跟":"，不能有空格，但":"后可有空格。
- 字段顺序没有意义，可任意排序。
- 字段原则上不能重复，除非该字段本身语义允许，如 Set-Cookie。
- 请求头：请求行+头部字段；响应头：响应行+头部字段

<img src="images\请求头.png" alt="请求头" style="zoom:50%;" />

<img src="images\响应头.png" alt="响应头" style="zoom:50%;" />

**常用头部字段**

HTTP 协议规定了非常多的头部字段，实现各种各样的功能，但基本上可以分为四大类：

1. 通用字段：在请求头和响应头里都可以出现；
2. 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；

3. 响应字段：仅能出现在响应头里，补充说明响应报文的信息；

4. 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。

常见的有：

- **Host**字段，请求字段 ，唯一一个 HTTP/1.1 规范里要求必须出现的字段。告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择，有点像是一个简单的“路由重定向”。
- **User-Agent**字段，请求字段，使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面。
- **Data**字段，通用字段，但通常出现在响应头中，表示HTTP报文创建的时间，客户端可以使用这个时间再搭配其它字段决定缓存策略。
- **Server**字段，响应字段，告诉客户端当前正在提供 Web 服务的软件名称和版本号。
- **Content-Length**字段，实体字段，表示报文里body的长度，也就是实体数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输。

## 请求方法

> 请求方法是客户端发出的、要求服务器执行的、对资源的一种操作。
>
> 请求方法是对服务器的“指示”，真正应如何处理由服务器来决定。

目前 HTTP/1.1 规定了8中方法，单词**都必须是大写的形式**。

- GET：获取资源，可以理解为读取或者下载数据；
2. HEAD：获取资源的元信息；
3. POST：向资源提交数据，相当于写入或上传数据；
4. PUT：类似 POST；
5. DELETE：删除资源；
6. CONNECT：建立特殊的连接隧道；
7. OPTIONS：列出可对资源实行的方法；
8. TRACE：追踪请求 - 响应的传输路径。

这些方法有点像对文件或数据库的“增删改查”，但动作操作目标是远程服务器的资源，只能有客户端“请求”或“指示”服务器来完成。**服务器掌控着所有资源**，也就有绝对的决策权力。它收到 HTTP 请求报文后，看到里面的请求方法，可以执行也可以拒绝，或者改变动作的含义。

**GET方法**

- 含义是请求**从服务器获取资源**，这个资源可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据。

- GET 方法虽然基本动作比较简单，但搭配 URI 和其他头字段就能实现对资源更精细的操作。如，在URI后使用`#`就可以获取页面后直接定位到某个标签所在位置；使用 `If-Modified-Since`字段就变成了“有条件的请求”；使用`Range`字段就是“范围请求”。

**HEAD**方法

- 与 GET 方法类似，也是请求从服务器获取资源，服务器的处理机制也是一样的，但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的“元信息”。

**POST/PUT方法**

- POST向 URI 指定的资源提交数据，数据就放在报文的 body 里。
- PUT 的作用与 POST 类似，也可以向服务器提交数据，与 POST 存在微妙的不同，通常 POST 表示的是“新建”“create”的含义，而 PUT 则是“修改”“update”的含义

**DELETE**方法指示服务器删除资源。

**CONNECT**方法要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。

**OPTIONS**方法要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回。

**TRACE**方法多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。

还有一些其他的拓展方法如：MKCOL、COPY、MOVE、LOCK、UNLOCK、PATCH

**安全与幂等**

- **安全**是指请求方法不会“破坏”服务器上的资源，即不会对服务器上的资源造成实质的修改。按照这个定义，只有GET和HEAD是安全的，因为它们是“只读”操作，只要服务器不故意曲解请求方法的处理方式，无论 GET 和 HEAD 操作多少次，服务器上的数据都是“安全的”。
- **幂等**意思是多次执行相同的操作，结果也都是相同的，即多次“幂”后结果“相等”。GET 和 HEAD 既是安全的也是幂等的，DELETE可以多次删除同一个资源，效果都是“资源不存在”，所以也是幂等的。POST 是“新增或提交数据”，多次提交数据会创建多个资源，所以不是幂等的；而 PUT是“替换或更新数据”，多次更新一个资源，资源还是会第一次更新的状态，所以是幂等的。

**GET 和 POST 有什么区别**

首先最直观的是语义上的区别。

而后又有这样一些具体的差别:

- 从**缓存**的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会。
- 从**编码**的角度，GET 只能进行 URL 编码，只能接收 ASCII 字符，而 POST 没有限制。
- 从**参数**的角度，GET 一般放在 URL 中，因此不安全，POST 放在请求体中，更适合传输敏感信息。
- 从**幂等性**的角度，`GET`是**幂等**的，而`POST`不是。(`幂等`表示执行相同的操作，结果也是相同的)
- 从**TCP**的角度，GET 请求会把请求报文一次性发出去，而 POST 会分为两个 TCP 数据包，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分。(**火狐**浏览器除外，它的 POST 请求只发一个 TCP 包)

## URI

URI即**统一资源标识符**（Uniform Resource Identifier），包含URL和URN两部分。在http世界用的网址实际上是URL--**统一资源定位符**（Uniform Resource Locator）。

URI 本质上是一个字符串，这个字符串的作用是**唯一地标记资源的位置或者名字**。它不仅能够标记万维网的资源，也可以标记如邮件系统、本地文件系统等任意资源。而“资源”既可以是存在磁盘上的静态文本、页面数据，也可以是由 Java、PHP 提供的动态服务。

**格式**

<img src="images\URI.png" alt="URI" style="zoom: 67%;" />

- **scheme**，**方案名**或**协议名**，表示**资源应该使用哪种协议**来访问。常见的有http、https，还有不常见的例如ftp、ldap、file、news等。后面必须和`://`连在一起。浏览器或者你的应用程序看到 URI 里的 scheme，就知道下一步该怎么走了，会调用相应的 HTTP 或者 HTTPS 下层API。
- **authority**，表示**资源所在的主机名**，通常形式是”host:port”，即主机名加端口号。主机名可以是IP地址或域名形式，端口号有时可省略。HTTP默认端口号80，HTTPS默认端口号443。
- **path标记资源所在位置**，有了协议名和主机地址、端口号和path，就可以连接服务器访问资源了。
- **query**，“key-value”字符串，多个键值对用`&`隔开，表示对资源附加的额外要求。

**完整格式**

<img src="images\URI2.png" alt="URI" style="zoom: 67%;" />

- 第一个多出的部分是协议名之后、主机名之前的身份信息“**user:passwd@**”，表示登录主机时的用户名和密码，但现在已经不推荐使用这种形式了（RFC7230），因为它把敏感信息以明文形式暴露出来，存在严重的安全隐患。
- **#fragment**，它是 URI 所定位的资源内部的一个“锚点”或者说是“标签”，浏览器可以在获取资源后直接跳转到它指示的位置。片段标识符仅能由浏览器这样的客户端使用，浏览器不会把带”#fragment”的URI发送给服务器。

**URI编码**

- **在 URI 里只能使用 ASCII 码**，某些特殊的 URI，会在 path、query 里出现“@&?"等起界定符作用的字符，会导致 URI 解析错误。所以URI引入了编码机制，对于 ASCII 码以外的字符集和特殊字符做一个特殊的操作，把它们转换成与 URI 语义不冲突的形式。这在 RFC 规范里称为“escape”和“unescape”，俗称“**转义**”。
- URI 转义的规则是直接把非 ASCII 码或特殊字符转换成**十六进制字节值**，然后前面再加上一个“**%**”。如空格被转义为“%20”，？被转义为“%3F”，而中文、日文等则通常使用UTF-8编码后再转义。
- 有了这个编码规则后，URI 就可以支持任意的字符集用任何语言来标记资源

## 响应状态码

> 状态码：以代码的形式表示服务器对请求的处理结果。客户端可以依据代码适时转换
> 处理状态，例如继续发送请求、切换协议，重定向跳转等。

RFC标准把状态码分成了5类。

- **1xx**：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；
- **2xx**：成功，报文已经收到并被正确处理；
- **3xx**：重定向，资源位置发生变化，需要客户端重新发送请求；
- **4xx**：客户端错误，请求报文有误，服务器无法处理；
- **5××**：服务器错误，服务器在处理请求时内部发生了错误。

在HTTP协议中，正确地理解并应用这些状态码不是客户端或服务器单方的责任，而是双方共同的责任。

- 客户端作为请求发起方，获取响应报文后，需要通过状态码知道请求是否被正确处理，是否要再次发送请求，如果出错了原因又是什么。这样才能进行下一步的动作，要么发送新请求，要么改正错误重发请求。
- 服务器端作为请求的接收方，也应该很好地运用状态码。在处理请求时，选择最恰当的状态码回复客户端，告知客户端处理的结果，指示客户端下一步应该如何行动。

目前 RFC 标准里总共有 41 个状态码，但状态码的定义是开放的，允许自行扩展。

常见的一些状态码

**1xx**

- **101 Switching Protocols**意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。

**2xx**

- **200 OK**是见得最多的成功状态码。通常在响应体中放有数据。
- **204 No Content**含义与 200 相同，但响应头后没有 body 数据。
- **206 Partial Content**是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现。通常伴随着头字段`Content-Range`。

**3xx**

- **301 Moved Permanently**即永久重定向，含义是此次请求的资源已经不存在，需要改用新的URI再次访问，对应着**302 Found**，即临时重定向，含义是请求的资源还在，但需要暂时用另一个URI访问。都会在响应头里使用字段**Location**指明后续要跳转的 URI。
- 比如你的网站从 HTTP 升级到了 HTTPS 了，以前的站点再也不用了，应当返回`301`，这个时候浏览器默认会做缓存优化，在第二次访问的时候自动访问重定向的那个地址。而如果只是暂时不可用，那么直接返回`302`即可，和`301`不同的是，浏览器并不会做缓存优化。
- **304 Not Modified**: 当协商缓存命中时会返回这个状态码。它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”
- 使用重定向时需要当心性能损耗，还要避免出现循环跳转。

**4xx**

- **400 Bad Request**: 开发者经常看到一头雾水，只是笼统地提示了一下错误，并不知道哪里出错了。
- **403 Forbidden**: 这实际上并不是客户端请求出错，而是服务器禁止访问，原因有很多，比如法律禁止、信息敏感。
- **404 Not Found**: 资源未找到，表示没在服务器上找到相应的资源。
- **405 Method Not Allowed**: 请求方法不被服务器端允许。
- **406 Not Acceptable**: 资源无法满足客户端的条件。
- **408 Request Timeout**: 服务器等待了太长时间。
- **409 Conflict**: 多个请求发生了冲突。
- **413 Request Entity Too Large**: 请求体的数据过大。
- **414 Request-URI Too Long**: 请求行里的 URI 太大。
- **429 Too Many Request**: 客户端发送的请求过多。
- **431 Request Header Fields Too Large**请求头的某个字段或总体太大。

**5xx**

- **500 Internal Server Error**: 仅仅告诉你服务器出错了，出了啥错咱也不知道。
- **501 Not Implemented**: 表示客户端请求的功能还不支持。
- **502 Bad Gateway**: 服务器作为网关或者代理时返回的错误码，服务器自身是正常的，但访问的时候出错了，啥错误咱也不知道。
- **503 Service Unavailable**: 表示服务器当前很忙，暂时无法响应服务。以 503 响应报文里通常还会有一个“**Retry-After**”字段，指示客户端可以在多久以后再次尝试发送请求。

## HTTP特点及缺点

**特点**

- **灵活可扩展**，主要体现在两个方面。一个是语义上的自由，只规定了基本格式，比如空格分隔单词，换行分隔字段，其他的各个部分都没有严格的语法限制。另一个是传输形式的多样性，不仅仅可以传输文本，还能传输图片、视频等任意数据，非常方便。
- **可靠传输**， HTTP 协议是基于 TCP/IP 的，因此把这一特性继承了下来。它对实际传输的数据（entity）做了一层包装，加上一个头，然后调用 Socket API，通过 TCP/IP 协议栈发送或者接收。

- **请求—应答**，也就是`一发一收`、`有来有回`， 当然这个请求方和应答方不单单指客户端和服务器之间，如果某台服务器作为代理来连接后端的服务端，那么这台服务器也会扮演**请求方**的角色。

- **无状态**， 这里的状态是指**通信过程的上下文信息**，HTTP 本质上是无状态的，每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。

**双刃剑**

> 我们在讨论一个东西的优缺点时，需要分场景来看的。

- **无状态**
  - 在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，那么这时候无状态就是 http 的缺点了。
  - 但与此同时，另外一些应用仅仅只是为了获取一些数据，不需要保存连接上下文信息，无状态反而减少了网络开销，成为了 http 的优点。

- **明文传输**
  - “明文”意思是协议里的报文（准确说是头部）不使用二进制数据，而是用简单可阅读的文本形式。
  - 明文传输为我们开发调试工作带来了极大便利。
  - 但同时也让 HTTP 的报文信息暴露给了外界，给攻击者也提供了便利。`WIFI陷阱`就是利用 HTTP 明文传输的缺点，诱导你连上热点，然后疯狂抓你所有的流量，从而拿到你的敏感信息。

**缺点**

- **不安全**：主要体现在“身份认证”和“完整性校验”两反面。
  - HTTP没有提供有效手段来确认通信双方的真实身份。虽然协议里有一个基本认证机制，但因为是明文传输，这个机制很容易被攻破。
  - HTTP不支持“完整性校验”，数据在传输过程中容易被窜改而无法验证真伪。
- **队头阻塞问题**：当 http 开启长连接时，共用一个 TCP 连接，同一时刻只能处理一个请求，那么当前请求耗时过长的情况下，其它的请求只能处于阻塞状态，也就是著名的**队头阻塞**问题。（当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。）

##  对 Accept 系列字段了解多少？

HTTP 协议使用 Accept 请求头字段和 Content实体头字段，用于客户端和服务器就语言与编码进行“**内容协商**”。也就是说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。

对于`Accept`系列字段的介绍分为四个部分: **数据格式**、**压缩方式**、**支持语言**和**字符集**。

### 数据格式

前面谈到 HTTP 灵活的特性，它支持非常多的数据格式，那么这么多格式的数据一起到达客户端，客户端怎么知道它的格式呢？

当然，最低效的方式是直接猜，有没有更好的方式呢？直接指定可以吗？

答案是肯定的。不过首先需要介绍一个标准——**MIME**(Multipurpose Internet Mail Extensions, **多用途互联网邮件扩展**)。它首先用在电子邮件系统中，让邮件可以发任意类型的数据，这对于 HTTP 来说也是通用的。

因此，HTTP 从**MIME type**取了一部分来标记报文 body 部分的数据类型，这些类型体现在`Content-Type`这个字段，当然这是针对于发送端而言，接收端想要收到特定类型的数据，也可以用`Accept`字段。

具体而言，这两个字段的取值可以分为下面几类:

- **text**：即文本格式的可读数据。如text/html，表示超文本文档；text/plain，表示纯文本；text/css表示样式表等
- **image**：即图像文件，有image/gif、image/jpeg、image/png等
- **audio/video**：音频和视频数据，例如audio/mpeg、video/mp4等
- **application**：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。如application/json, application/javascript, application/pdf, application/octet-stream（不透明的二进制数据）

### 压缩方式

HTPP在传输时为了节约带宽，有时还会压缩数据，为了不然浏览器继续“猜”，还需要有一个“**Encoding type**”告诉数据是用的什么编码格式，采取什么样的压缩方式就体现在了发送方的`Content-Encoding`字段上， 同样的，接收什么样的压缩方式体现在了接受方的`Accept-Encoding`字段上。

- **gzip**：GUN zip压缩格式，也是互联网最流行的压缩格式
- **deflate**：zlib(deflate)压缩格式
- **br**：一种专门为HTTP优化的新压缩算法（Brotli)

```http
# 发送端
Content-Encoding: gzip
# 接收端
Accept-Encoding: gzip
```

### 支持语言

对于发送方而言，还有一个`Content-Language`字段，在需要实现国际化的方案当中，可以用来指定支持的语言，在接受方对应的字段为`Accept-Language`。如:

```js
// 发送端
Content-Language: zh-CN, zh, en
// 接收端
Accept-Language: zh-CN, zh, en
```

### 字符集

最后是一个比较特殊的字段, 在接收端对应为`Accept-Charset`，指定可以接受的字符集，而在发送端并没有对应的`Content-Charset`, 而是直接放在了`Content-Type`中，以**charset**属性指定。如:

```js
// 发送端
Content-Type: text/html; charset=utf-8
// 接收端
Accept-Charset: charset=utf-8
```

### 总结

```
Accept ---->  Content-Type
Accept-Encoding ----> Content-Encoding
Accept-Language ----> Content-Language
Accept-Charset ---->Content-Type
```



## HTPP传输大文件方法 

 HTTP 可以传输很多种类的数据，不仅是文本，也能传输图片、音频和视频。

如何在有限的带宽下高效快捷地传输这些大文件就成了一个重要的课题。

### 数据压缩

前面讲过，通常浏览器在发送请求时都会带着`Accept-Encoding`头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进`Content-Encoding`响应头里，再把原数据压缩后发给浏览器。

如果压缩率有50%，那么就相当于在带宽不变的情况下网速提升了一倍，加速的效果是非常明显的。

但gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了。

不过数据压缩在处理文本的时候效果还是很好的，所以各大网站的服务器都会使用这个手段作为“保底”。例如，在Nginx 里就会使用“gzip on”指令，启用对“text/html”的压缩。

### 分块传输（HTTP传输不定长数据方法）

**思想**是：将大文件分解成多个小块，把这些小块分批发给浏览器，浏览器收到后再组装复原。这样浏览器和服务器都不用在内存里保存文件的全部，每次只收发一小部分，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。

这种“**化整为零**”的思路在 HTTP 协议里就是“**chunked**”分块传输编码，在**响应报文**里用头字段“**Transfer-Encoding: chunked**”来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。表现效果：**基于长连接持续推送动态内容**。

“**Transfer-Encoding: chunked**”和“**Content-Length**”这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked）。【chunked编码用在“流式”收发数据的时候，通常数据是即时生成的，也就是动态数据。】

**分块传输编码规则**

1. 每个分块包含两个部分，长度头和数据块；
2. 长度头是以 CRLF（回车换行，即\r\n）结尾的一行明文，用 16 进制数字表示长度；
3. 数据块紧跟在长度头后，最后也用 CRLF 结尾，但数据不包含 CRLF；
4. 最后用一个长度为 0 的块表示结束，即“0\r\n\r\n”。

![分块传输](images\分块传输.png)

### 范围请求

> 范围请求可以只获取**部分数据**，即“分块请求”，实现**视频拖拽**或者**断点续传**或**多段下载**，使用请求头字段“**Range**”和响应头字段“**Content-Range**”，响应状态码必须是 **206**；
>
> 也可以一次请求**多个范围**，这时候响应报文的数据类型是“**multipart/byteranges**”，body 里的多个部分会用**boundary** 字符串分隔。

如果想获取一个大文件其中的片段数据，分块传输并没有这个能力，于是HTTP协议提出了**范围请求**（range requeests）的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于**客户端的“化整为零”**。

以**服务器必须在响应头里**使用字段“**Accept-Ranges: bytes**”明确告知客户端：“我是支持范围请求的”。如果服务器不支持，可以发送`Accept-Ranges:none`，或不发送该字段，这样客户端就认为服务器没有实现范围请求功能，只能发整块文件。

**Ranges字段**

而对于客户端而言，它需要指定请求哪一部分，通过`Range`这个请求头字段确定，格式为`bytes=x-y`。接下来就来讨论一下这个 Range 的书写格式:

- **0-499**表示从开始到第 499 个字节。
- **500**- 表示从第 500 字节到文件终点。
- **-100**表示文件的最后100个字节。

服务器收到请求之后

- 首先验证范围**是否合法**，如果越界了那么返回`416`错误码，否则读取相应片段，返回`206`状态码。

- 同时，服务器需要添加响应头字段`Content-Range`，这个字段的格式根据请求头中`Range`字段的不同而有所差异。

- 最后就是发送数据了，直接把片段用TCP发给客户端，一个范围请求就算处理完了。

请求**单段数据**和请求**多段数据**，响应头是不一样的。

例如：

```js
// 单段数据
Range: bytes=0-9
// 多段数据
Range: bytes=0-9, 30-39
```

**单段数据**

返回响应：

```js
HTTP/1.1 206 Partial Content
Content-Length: 10
Accept-Ranges: bytes
Content-Range: bytes 0-9/100

i am xxxxx
```

值得注意的是`Content-Range`字段，`0-9`表示请求的返回，`100`表示资源的总大小，很好理解。

**多段数据**

```js
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000010101
Content-Length: 189
Connection: keep-alive
Accept-Ranges: bytes


--00000010101
Content-Type: text/plain
Content-Range: bytes 0-9/96

i am xxxxx
--00000010101
Content-Type: text/plain
Content-Range: bytes 20-29/96

eex jspy e
--00000010101--

```

这个时候出现了一个非常关键的字段`Content-Type: multipart/byteranges;boundary=00000010101`，它代表了信息量是这样的:

- 请求一定是多段数据请求
- 响应体中的分隔符是 00000010101

因此，在响应体中各段数据之间会由这里指定的分隔符分开，而且在最后的分隔末尾添上`--`表示结束。

**用途**

有了范围请求之后，HTTP 处理大文件就更加轻松了，看视频时可以根据时间点计算出文件的 Range，不用下载整个文件，直接精确获取片段所在的数据内容。

不仅看视频的拖拽进度需要范围请求，常用的下载工具里的多段下载、断点续传也是基于它实现的，要点是：

- 先发个 HEAD，看服务器是否支持范围请求，同时获取文件的大小；
- 开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据；
- 下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了。

## 长连接与短连接

HTTP协议最初（0.9/1.0）是个很简单的协议，通信过程也采用了简单的”**请求-应答**“方式。它底层的数据传输基于TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应后会立即关闭连接。【TCP建立连接要有“三次握手”，关闭连接是“四次挥手”，这都是很耗时的操作。】

**短连接**：客户端和服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态。

**长连接**：客户端与服务器保持长时间的连接状态。对性能改善明显。

![长连接和短连接](images\长连接和短连接.png)

可以在请求头明确要求使用长连接机制：`Connection: keep-alive;`

如果服务器支持长连接，会在响应报文放字段：`Connection: keep-alive`。默认开启长连接。

在客户端，可在请求头加上`Connection: close`字段来告诉服务器，这次通信后就关闭连接。

**长连接缺点**：因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。

服务端通常不会主动关闭连接，但也可以使用一些策略，拿Nginx举例，它有两种方式：

- `keepalive_timeouot`指令设置长连接超时时间。
- `keepalive_requests`指令设置长连接上可发送的最大请求次数。

另外，客户端和服务器都可以在报文里附加通用头字段`Keep-Alive: timeout=value`，限定长连接的超时时间。但这个字段的约束力并不强，通信的双方可能并不会遵守，所以不太常见。

## HTTP/1.1 如何解决 HTTP 的队头阻塞问题？

**队头阻塞**

HTTP 传输是基于`请求-应答`的模式进行的，报文必须是一发一收，但值得注意的是，里面的任务被放在一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理。这就是著名的`HTTP队头阻塞`问题。

![队头阻塞](images\队头阻塞.png)

**并发连接**

对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务。在RFC2616规定过客户端最多并发 2 个连接，不过事实上在现在的浏览器标准中，这个上限要多很多，Chrome 中是 6 个。

但其实，即使是提高了并发连接，还是不能满足人们对性能的需求。

**域名分片**

一个域名不是可以并发 6 个长连接吗？那我就多分几个域名。

比如 content1.sampson.com 、content2.sampson.com。

这样一个``sampson.com`域名下可以分出非常多的二级域名，而它们都指向同样的一台服务器，能够并发的长连接数更多了，事实上也更好地解决了队头阻塞的问题。

## HTPP的Cookie机制

### Cookie简介

前面说到了 HTTP 是一个无状态的协议，每次 http 请求都是独立、无关的，默认不需要保留状态信息。但有时候需要保存一些状态，怎么办呢？

HTTP 为此引入了 Cookie。Cookie 本质上就是浏览器里面存储的一个很小的文本文件，内部以键值对的方式来存储。向同一个域名下发送请求，都会携带相同的 Cookie，服务器拿到 Cookie 进行解析，便能拿到客户端的状态。而服务端可以通过响应头中的`Set-Cookie`字段来对客户端写入`Cookie`。举例如下:

```
// 请求头
Cookie: a=xxx;b=xxx
// 响应头
Set-Cookie: a=xxx
set-Cookie: b=xxx
```

### Cookie的属性

>Cookie 就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息。所以，就需要在“key=value”外再用一些手段来保护，防止外泄或窃取，这些手段就是 Cookie 的属性。

**生存周期**

Cookie 的有效期可以通过**Expires**和**Max-Age**两个属性来设置。

- **Expires**即`过期时间`
- **Max-Age**用的是一段时间间隔，单位是秒，从浏览器收到报文开始计算。

若 Cookie 过期，则这个 Cookie 会被删除，并不会发送给服务端。

若两者同时设置，浏览器优先采用 Max-Age 计算失效期。

**作用域**

关于作用域也有两个属性: **Domain**和**path**, 给 **Cookie** 绑定了域名和路径，在发送请求之前，发现域名或者路径和这两个属性不匹配，那么就不会带上 Cookie。值得注意的是，对于路径来说，`/`表示域名下的任意路径都允许使用 Cookie。

**安全相关**

> 在 JS 脚本里可以用 document.cookie 来读写 Cookie 数据，这就带来了安全隐患，有可能会导致“跨站脚本”（XSS）攻击窃取数据。

如果带上`Secure`，说明只能通过 HTTPS 传输 cookie。

如果 cookie 字段带上`HttpOnly`，那么说明只能通过 HTTP 协议传输，不能通过 JS 访问，这也是预防 XSS 攻击的重要手段。

相应的，对于 CSRF 攻击的预防，也有`SameSite`属性。

`SameSite`可以设置为三个值，`Strict`、`Lax`和`None`。

**a.** 在`Strict`模式下，浏览器完全禁止第三方请求携带Cookie。比如请求sampson.com网站只能在sampson.com域名当中请求才能携带 Cookie，在其他网站请求都不能。

**b.** 在`Lax`模式，就宽松一点了，但是只能在  get/head 方法提交表单 或者 a 标签发送 get 请求  的情况下可以携带 Cookie，其他情况均不能。

**c.** 在`None`模式下，也就是默认模式，请求会自动携带上 Cookie。

### Cookie的缺点

1. 容量缺陷。Cookie 的体积上限只有`4KB`，只能用来存储少量的信息。
2. 性能缺陷。Cookie 紧跟域名，不管域名下面的某一个地址需不需要这个 Cookie ，请求都会携带上完整的 Cookie，这样随着请求数的增多，其实会造成巨大的性能浪费的，因为请求携带了很多不必要的内容。但可以通过`Domain`和`Path`指定**作用域**来解决。
3. 安全缺陷。由于 Cookie 以纯文本的形式在浏览器和服务器中传递，很容易被非法用户截获，然后进行一系列的篡改，在 Cookie 的有效期内重新发送给服务器，这是相当危险的。另外，在`HttpOnly`为 false 的情况下，Cookie 信息能直接通过 JS 脚本来读取。

### Cookie用途

- **身份识别**，保存用户的登录信息，实现会话事务。
- **广告追踪**



## HTTP的代理服务

我们知道在 HTTP 是基于`请求-响应`模型的协议，一般由客户端发请求，服务器来进行响应。

![http代理](images\http代理.png)

当然，也有特殊情况，就是代理服务器的情况。引入代理之后，作为代理的服务器相当于一个中间人的角色，对于客户端而言，表现为服务器进行响应；而对于源服务器，表现为客户端发起请求，具有**双重身份**。

那代理服务器到底是用来做什么的呢？

### 功能

1. **负载均衡**。客户端的请求只会先到达代理服务器，后面到底有多少源服务器，IP 都是多少，客户端是不知道的。因此，这个代理服务器可以拿到这个请求之后，可以通过特定的算法分发给不同的源服务器，让各台源服务器的负载尽量平均。当然，这样的算法有很多，包括**随机算法**、**轮询**、**一致性hash**、**LRU**`(最近最少使用)`等等。
2. **保障安全**。利用**心跳**机制监控后台的服务器，一旦发现故障机就将其踢出集群。并且对于上下行的数据进行过滤，对非法 IP 限流，这些都是代理服务器的工作。
3. **缓存代理**。将内容缓存到代理服务器，使得客户端可以直接从代理服务器获得而不用到源服务器那里。

### 相关头部字段

#### Via

代理服务器需要标明自己的身份，在 HTTP 传输中留下自己的痕迹，怎么办呢？

Via 是一个通用字段，请求头或响应头里都可以出现。每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾。

通过`Via`字段来记录。举个例子，现在中间有两台代理服务器，在客户端发送请求后会经历这样一个过程:

```
客户端 -> 代理1 -> 代理2 -> 源服务器
```

在源服务器收到请求后，会在`请求头`拿到这个字段:

```
Via: proxy_server1, proxy_server2
```

而源服务器响应时，最终在客户端会拿到这样的`响应头`:

```
Via: proxy_server2, proxy_server1
```

可以看到，`Via`中代理的顺序即为在 HTTP 传输中报文传达的顺序。

Via 字段只解决了客户端和源服务器判断是否存在代理的问题，还不能知道对方的真实信
息。
但服务器的 IP 地址应该是保密的，关系到企业的内网安全，所以一般不会让客户端知道。
不过反过来，通常服务器需要知道客户端的真实 IP 地址，方便做访问控制、用户画像、统
计分析。于是出现了很多”事实上的标准“，如下面两种。

#### X-Forwarded-For

“X-Forwarded-For”的字面意思是“**为谁而转发**”，形式上和“Via”差不多，也是每经过一个代理节点就会在字段里追加一个信息。但“**Via**”追加的是**代理主机名**（或者域名），而“**X-Forwarded-For**”追加的是**请求方的 IP 地址**。所以，在字段里最左边的 IP地址就客户端的地址。

#### X-Real-IP

是一种获取用户真实 IP 的字段，不管中间经过多少代理，这个字段始终记录最初的客户端的IP。

相应的，还有`X-Forwarded-Host`和`X-Forwarded-Proto`，分别记录**客户端**(注意哦，不包括代理)的`域名`和`协议名`。

### X-Forwarded-For产生的问题

`X-Forwarded-For`这个字段记录的是请求方的 IP

但是这会产生两个问题:

1. 意味着代理必须解析 HTTP 请求头，然后修改，比直接转发数据性能下降。
2. 在 HTTPS 通信加密的过程中，原始报文是不允许修改的。

由此产生了**代理协议**，一般使用明文版本，只需要在 HTTP 请求行上面加上这样格式的文本即可:

```
// PROXY + TCP4/TCP6 + 请求方地址 + 接收方地址 + 请求端口 + 接收端口
PROXY TCP4 0.0.0.1 0.0.0.2 1111 2222
GET / HTTP/1.1
...
```

这样就可以解决`X-Forwarded-For`带来的问题了。

## HTTP缓存及缓存代理

关于`强缓存`和`协商缓存`的内容，前面已经总结过了，这里简单说一下：

首先通过 `Cache-Control` 验证强缓存是否可用

- 如果强缓存可用，直接使用
- 否则进入协商缓存，即发送 HTTP 请求，服务器通过请求头中的`If-Modified-Since`或者`If-None-Match`这些**条件请求**字段检查资源是否更新
  - 若资源更新，返回资源和200状态码
  - 否则，返回304，告诉浏览器直接从缓存获取资源

这一节我们主要来说说另外一种缓存方式: **代理缓存**。

### 为什么产生代理缓存？

对于源服务器来说，它也是有缓存的，比如**Redis, Memcache**，但对于 HTTP 缓存来说，如果每次客户端缓存失效都要到源服务器获取，那给源服务器的压力是很大的。

由此引入了**缓存代理**的机制。让`代理服务器`接管一部分的服务端HTTP缓存，客户端缓存过期后**就近**到代理缓存中获取，代理缓存过期了才请求源服务器，这样流量巨大的时候能明显降低源服务器的压力。

那缓存代理究竟是如何做到的呢？

总的来说，缓存代理的控制分为两部分，一部分是**源服务器**端的控制，一部分是**客户端**的控制。

### 源服务器的缓存控制

#### private 和 public

在源服务器的响应头中，会加上`Cache-Control`这个字段进行缓存控制字段，那么它的值当中可以加入`private`或者`public`表示是否允许代理服务器缓存，前者禁止，后者为允许。

比如对于一些非常私密的数据，如果缓存到代理服务器，别人直接访问代理就可以拿到这些数据，是非常危险的，因此对于这些数据一般是不会允许代理服务器进行缓存的，将响应头部的`Cache-Control`设为`private`，而不是`public`。

#### proxy-revalidate

`must-revalidate`的意思是**客户端**缓存过期就去源服务器获取，而`proxy-revalidate`则表示**代理服务器**的缓存过期后到源服务器获取。

#### s-maxage

`s`是`share`的意思，限定了缓存在代理服务器中可以存放多久，和限制客户端缓存时间的`max-age`并不冲突。

讲了这几个字段，我们不妨来举个小例子，源服务器在响应头中加入这样一个字段:

```
Cache-Control: public, max-age=1000, s-maxage=2000
```

相当于源服务器说: 我这个响应是允许代理服务器缓存的，客户端缓存过期了到代理中拿，并且在客户端的缓存时间为 1000 秒，在代理服务器中的缓存时间为 2000 s。

### 客户端的缓存控制

#### max-stale 和 min-fresh

在客户端的请求头中，可以加入这两个字段，来对代理服务器上的缓存进行**宽容**和**限制**操作。比如：

```
max-stale: 5
```

表示客户端到代理服务器上拿缓存的时候，即使代理缓存过期了也不要紧，只要过期时间在**5秒之内**，还是可以从代理中获取的。

又比如:

```
min-fresh: 5
```

表示代理缓存需要一定的新鲜度，不要等到缓存刚好到期再拿，一定要在**到期前 5 秒**之前的时间拿，否则拿不到。

#### only-if-cached

这个字段加上后表示客户端只会接受代理缓存，而不会接受源服务器的响应。如果代理缓存无效，则直接返回`504（Gateway Timeout）`。

非对称加密是公钥可以解私钥，私钥可以解公钥。 大体的流程是  1. Client Hello : C -> S client-random + 协议号 + 支持的密码套件 2. Server Hello : S -> C 证书(包含公钥) + server-random + 协商的加密方式 比如 对称加密 AES + 非对称加密 ECDHE 3. 客户端拿到证书，通过内置的 CA 公钥 + 对应的摘要算法去验签，验签的目的在于核实这次请求的身份。看看证书是否被吊销，是否被篡改了等。没问题后，又生成随机数 pre-master 通过公钥+非对称加密的方式加密报文，通过 Client Key Exchange 发送 【这时候就算黑客拿到报文没有服务器的私钥也解不出来】 4. Client Key Exchange: C -> S 通过服务器的私钥解密，拿到 pre-master 后面两端都可以通过 client-random + server-random + pre-master 生成一样的会话密钥，使用对称加密的方式进行通信。

## TLS1.2握手的过程是怎样的

HTTP 是明文传输的协议，传输保文对外完全透明，非常不安全，那如何进一步保证安全性呢？

由此产生了 `HTTPS`，其实它并不是一个新的协议，而是在 HTTP 下面增加了一层 SSL/TLS 协议，简单的讲，**HTTPS = HTTP + SSL/TLS**。

那什么是 SSL/TLS 呢？

> SSL/TLS 是信息安全领域中的权威标准，采用多种先进的加密技术保证通信安全；

SSL 即安全套接层（Secure Sockets Layer），在 OSI 七层模型中处于会话层(第 5 层)。之前 SSL 出过三个大版本，当它发展到第三个大版本的时候才被标准化，成为 TLS（传输层安全，Transport Layer Security），并被当做 TLS1.0 的版本，准确地说，**TLS1.0 = SSL3.1**。

现在主流的版本是 TLS/1.2, 之前的 TLS1.0、TLS1.1 都被认为是不安全的，在不久的将来会被完全淘汰。因此我们接下来主要讨论的是 TLS1.2, 当然在 2018 年推出了更加优秀的 TLS1.3，大大优化了 TLS 握手过程。

### 传统 RSA 握手

先来说说传统的 TLS 握手，参见之前写的的[文章]()，其中也介绍到了`对称加密`和`非对称加密`的概念，建议大家去读一读，不再赘述。之所以称它为 RSA 版本，是因为它在加解密`pre_random`的时候采用的是 RSA 算法。

### TLS 1.2 握手过程

![tls1.2连接过程](E:\前端の道\Daily_question\http相关\images\tls1.2连接过程.png)

#### step 1: Client Hello

首先，浏览器发送 client_random、TLS版本、加密套件列表。

client_random 是用来最终 secret 的一个参数。

加密套件列表是什么？我举个例子，加密套件列表一般张这样:

```
TLS_ECDHE_WITH_AES_128_GCM_SHA256
```

意思是`TLS`握手过程中，使用`ECDHE`算法生成`pre_random`，128位的`AES`算法进行对称加密，在对称加密的过程中使用主流的`GCM`分组模式，因为对称加密中很重要的一个问题就是如何分组。最后一个是哈希摘要算法，采用`SHA256`算法。

其中值得解释一下的是这个哈希摘要算法，试想一个这样的场景，服务端现在给客户端发消息来了，客户端并不知道此时的消息到底是服务端发的，还是中间人伪造的消息呢？现在引入这个哈希摘要算法，将服务端的证书信息通过**这个算法**生成一个摘要(可以理解为`比较短的字符串`)，用来**标识**这个服务端的身份，用私钥加密后把**加密后的标识**和**自己的公钥**传给客户端。客户端拿到**这个公钥**来解密，生成另外一份摘要。两个摘要进行对比，如果相同则能确认服务端的身份。这也就是所谓**数字签名**的原理。其中除了哈希算法，最重要的过程是**私钥加密，公钥解密**。

#### step 2: Server Hello

可以看到服务器一口气给客户端回复了非常多的内容。

`server_random`也是最后生成`secret`的一个参数, 同时确认 TLS 版本、需要使用的加密套件和自己的证书，这都不难理解。那剩下的`server_params`是干嘛的呢？

我们先埋个伏笔，现在你只需要知道，`server_random`到达了客户端。

#### step 3: Client 验证证书，生成secret

客户端验证服务端传来的`证书`和`签名`是否通过，如果验证通过，则传递`client_params`这个参数给服务器。

接着客户端通过`ECDHE`算法计算出`pre_random`，其中传入两个参数:**server_params**和**client_params**。现在你应该清楚这个两个参数的作用了吧，由于`ECDHE`基于`椭圆曲线离散对数`，这两个参数也称作`椭圆曲线的公钥`。

客户端现在拥有了`client_random`、`server_random`和`pre_random`，接下来将这三个数通过一个伪随机数函数来计算出最终的`secret`。

#### step4: Server 生成 secret

刚刚客户端不是传了`client_params`过来了吗？

现在服务端开始用`ECDHE`算法生成`pre_random`，接着用和客户端同样的伪随机数函数生成最后的`secret`。

#### 注意事项

TLS的过程基本上讲完了，但还有两点需要注意。

**第一**、实际上 TLS 握手是一个**双向认证**的过程，从 step1 中可以看到，客户端有能力验证服务器的身份，那服务器能不能验证客户端的身份呢？

当然是可以的。具体来说，在 `step3`中，客户端传送`client_params`，实际上给服务器传一个验证消息，让服务器将相同的验证流程(哈希摘要 + 私钥加密 + 公钥解密)走一遍，确认客户端的身份。

**第二**、当客户端生成`secret`后，会给服务端发送一个收尾的消息，告诉服务器之后的都用对称加密，对称加密的算法就用第一次约定的。服务器生成完`secret`也会向客户端发送一个收尾的消息，告诉客户端以后就直接用对称加密来通信。

这个收尾的消息包括两部分，一部分是`Change Cipher Spec`，意味着后面加密传输了，另一个是`Finished`消息，这个消息是对之前所有发送的数据做的**摘要**，对摘要进行加密，让对方验证一下。

当双方都验证通过之后，握手才正式结束。后面的 HTTP 正式开始传输加密报文。

#### RSA 和 ECDHE 握手过程的区别

1. ECDHE 握手，也就是主流的 TLS1.2 握手中，使用`ECDHE`实现`pre_random`的加密解密，没有用到 RSA。
2. 使用 ECDHE 还有一个特点，就是客户端发送完收尾消息后可以提前`抢跑`，直接发送 HTTP 报文，节省了一个 RTT，不必等到收尾消息到达服务器，然后等服务器返回收尾消息给自己，直接开始发请求。这也叫`TLS False Start`。

## TLS1.3 做了哪些改进？

TLS 1.2 虽然存在了 10 多年，经历了无数的考验，但历史的车轮总是不断向前的，为了获得更强的安全、更优秀的性能，在`2018年`就推出了 TLS1.3，对于`TLS1.2`做了一系列的改进，主要分为这几个部分:**强化安全**、**提高性能**。当然，推出TLS1.3的同时为**最大化兼容**TLS1.2做出了努力，比如增加了新的**扩展协议**。

### 强化安全

在 TLS1.3 中废除了非常多的加密算法，最后只保留五个加密套件:

- TLS_AES_128_GCM_SHA256
- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_GCM_8_SHA256

可以看到，最后剩下的对称加密算法只有 **AES** 和 **CHACHA20**，之前主流的也会这两种。分组模式也只剩下 **GCM** 和 **POLY1305**, 哈希摘要算法只剩下了 **SHA256** 和 **SHA384** 了。

那你可能会问了, 之前`RSA`这么重要的非对称加密算法怎么不在了？

我觉得有两方面的原因:

**第一**、2015年发现了`FREAK`攻击，即已经有人发现了 RSA 的漏洞，能够进行破解了。

**第二**、一旦私钥泄露，那么中间人可以通过私钥计算出之前所有报文的`secret`，破解之前所有的密文。

为什么？回到 RSA 握手的过程中，客户端拿到服务器的证书后，提取出服务器的公钥，然后生成`pre_random`并用**公钥**加密传给服务器，服务器通过**私钥**解密，从而拿到真实的`pre_random`。当中间人拿到了服务器私钥，并且截获之前所有报文的时候，那么就能拿到`pre_random`、`server_random`和`client_random`并根据对应的随机数函数生成`secret`，也就是拿到了 TLS 最终的会话密钥，每一个历史报文都能通过这样的方式进行破解。

但`ECDHE`在每次握手时都会生成临时的密钥对，即使私钥被破解，之前的历史消息并不会收到影响。这种一次破解并不影响历史信息的性质也叫**前向安全性**。

`RSA` 算法不具备前向安全性，而 `ECDHE` 具备，因此在 TLS1.3 中彻底取代了`RSA`。

### 提升性能

主要体现在TSL**握手改进**

大体的方式和 TLS1.2 差不多，不过和 TLS 1.2 相比少了一个 RTT， 服务端不必等待对方验证证书之后才拿到`client_params`，而是直接在第一次握手的时候就能够拿到, 拿到之后立即计算`secret`，节省了之前不必要的等待时间。同时，这也意味着在第一次握手的时候客户端需要传送更多的信息，一口气给传完。

这种 TLS 1.3 握手方式也被叫做**1-RTT握手**。但其实这种`1-RTT`的握手方式还是有一些优化的空间的，接下来我们来一一介绍这些优化方式。

#### 会话复用

会话复用有两种方式: **Session ID**和**Session Ticket**。

先说说最早出现的**Seesion ID**，具体做法是客户端和服务器首次连接后各自保存会话的 ID，并存储会话密钥，当再次连接时，客户端发送`ID`过来，服务器查找这个 ID 是否存在，如果找到了就直接复用之前的会话状态，会话密钥不用重新生成，直接用原来的那份。

但这种方式也存在一个弊端，就是当客户端数量庞大的时候，对服务端的存储压力非常大。

因而出现了第二种方式——**Session Ticket**。它的思路就是: 服务端的压力大，那就把压力分摊给客户端呗。具体来说，双方连接成功后，服务器加密会话信息，用**Session Ticket**消息发给客户端，让客户端保存下来。下次重连的时候，就把这个 Ticket 进行解密，验证它过没过期，如果没过期那就直接恢复之前的会话状态。

这种方式虽然减小了服务端的存储压力，但与带来了安全问题，即每次用一个固定的密钥来解密 Ticket 数据，一旦黑客拿到这个密钥，之前所有的历史记录也被破解了。因此为了尽量避免这样的问题，密钥需要定期进行更换。

总的来说，这些会话复用的技术在保证`1-RTT`的同时，也节省了生成会话密钥这些算法所消耗的时间，是一笔可观的性能提升。

#### PSK

刚刚说的都是`1-RTT`情况下的优化，那能不能优化到`0-RTT`呢？

答案是可以的。做法其实也很简单，在发送**Session Ticket**的同时带上应用数据，不用等到服务端确认，这种方式被称为`Pre-Shared Key`，即 PSK。

这种方式虽然方便，但也带来了安全问题。中间人截获`PSK`的数据，不断向服务器重复发，类似于 TCP 第一次握手携带数据，增加了服务器被攻击的风险。

### 总结

TLS1.3 在 TLS1.2 的基础上废除了大量的算法，提升了安全性。同时利用会话复用节省了重新生成密钥的时间，利用 PSK 做到了`0-RTT`连接。

## HTTP/2有哪些改进

由于 HTTPS 在安全方面已经做的非常好了，HTTP 改进的关注点放在了性能方面。对于 HTTP/2 而言，它对于性能的提升主要在于两点:

- 头部压缩
- 多路复用

当然还有一些颠覆性的功能实现:

- 设置请求优先级
- 服务器推送

这些重大的提升本质上也是为了解决 HTTP 本身的问题而产生的。接下来我们来看看 HTTP/2 解决了哪些问题，以及解决方式具体是如何的。

### 头部压缩

在 HTTP/1.1 及之前的时代，**请求体**一般会有响应的压缩编码过程，通过`Content-Encoding`头部字段来指定，但你有没有想过头部字段本身的压缩呢？当请求字段非常复杂的时候，尤其对于 GET 请求，请求报文几乎全是请求头，这个时候还是存在非常大的优化空间的。HTTP/2 针对头部字段，也采用了对应的压缩算法——HPACK，对请求头进行压缩。

HPACK 算法是专门为 HTTP/2 服务的，它主要的亮点有两个：

- 首先是在服务器和客户端之间建立哈希表，将用到的字段存放在这张表中，那么在传输的时候对于之前出现过的值，只需要把**索引**(比如0，1，2，...)传给对方即可，对方拿到索引查表就行了。这种**传索引**的方式，可以说让请求头字段得到极大程度的精简和复用。

<img src="E:\前端の道\Daily_question\http相关\images\http2头部压缩.png" alt="http2头部压缩" style="zoom:67%;" />

> HTTP/2 当中废除了起始行的概念，将起始行中的请求方法、URI、状态码转换成了头字段，不过这些字段都有一个":"前缀，用来和其它请求头区分开。

- 其次是对于整数和字符串进行**哈夫曼编码**，哈夫曼编码的原理就是先将所有出现的字符建立一张索引表，然后让出现次数多的字符对应的索引尽可能短，传输的时候也是传输这样的**索引序列**，可以达到非常高的压缩率。

### 多路复用

#### HTTP 队头阻塞

我们之前讨论了 HTTP 队头阻塞的问题，其根本原因在于HTTP 基于`请求-响应`的模型，在同一个 TCP 长连接中，前面的请求没有得到响应，后面的请求就会被阻塞。

后面我们又讨论到用**并发连接**和**域名分片**的方式来解决这个问题，但这并没有真正从 HTTP 本身的层面解决问题，只是增加了 TCP 连接，分摊风险而已。而且这么做也有弊端，多条 TCP 连接会竞争**有限的带宽**，让真正优先级高的请求不能优先处理。

而 HTTP/2 便从 HTTP 协议本身解决了`队头阻塞`问题。注意，这里并不是指的`TCP队头阻塞`，而是`HTTP队头阻塞`，两者并不是一回事。TCP 的队头阻塞是在`数据包`层面，单位是`数据包`，前一个报文没有收到便不会将后面收到的报文上传给 HTTP，而HTTP 的队头阻塞是在 `HTTP 请求-响应`层面，前一个请求没处理完，后面的请求就要阻塞住。两者所在的层次不一样。

那么 HTTP/2 如何来解决所谓的队头阻塞呢？

#### 二进制分帧

首先，HTTP/2 认为明文传输对机器而言太麻烦了，不方便计算机的解析，因为对于文本而言会有多义性的字符，比如回车换行到底是内容还是分隔符，在内部需要用到状态机去识别，效率比较低。于是 HTTP/2 干脆把报文全部换成二进制格式，全部传输`01`串，方便了机器的解析。

原来`Headers + Body`的报文格式如今被拆分成了一个个二进制的帧，用**Headers帧**存放头部字段，**Data帧**存放请求体数据。分帧之后，服务器看到的不再是一个个完整的 HTTP 请求报文，而是一堆乱序的二进制帧。这些二进制帧不存在先后关系，因此也就不会排队等待，也就没有了 HTTP 的队头阻塞问题。

通信双方都可以给对方发送二进制帧，这种二进制帧的**双向传输的序列**，也叫做`流`(Stream)。HTTP/2 用`流`来在一个 TCP 连接上来进行多个数据帧的通信，这就是**多路复用**的概念。

可能你会有一个疑问，既然是乱序首发，那最后如何来处理这些乱序的数据帧呢？

首先要声明的是，所谓的乱序，指的是不同 ID 的 Stream 是乱序的，但同一个 Stream ID 的帧一定是按顺序传输的。二进制帧到达后对方会将 Stream ID 相同的二进制帧组装成完整的**请求报文**和**响应报文**。当然，在二进制帧当中还有其他的一些字段，实现了**优先级**和**流量控制**等功能，我们放到下一节再来介绍。

### 服务器推送

另外值得一说的是 HTTP/2 的服务器推送(Server Push)。在 HTTP/2 当中，服务器已经不再是完全被动地接收请求，响应请求，它也能新建 stream 来给客户端发送消息，当 TCP 连接建立之后，比如浏览器请求一个 HTML 文件，服务器就可以在返回 HTML 的基础上，将 HTML 中引用到的其他资源文件一起返回给客户端，减少客户端的等待。

### 总结

当然，HTTP/2 新增那么多的特性，是不是 HTTP 的语法要重新学呢？不需要，HTTP/2 完全兼容之前 HTTP 的语法和语义，如**请求头、URI、状态码、头部字段**都没有改变，完全不用担心。同时，在安全方面，HTTP 也支持 TLS，并且现在主流的浏览器都公开只支持加密的 HTTP/2, 因此你现在能看到的 HTTP/2 也基本上都是跑在 TLS 上面的了。最后放一张分层图给大家参考:

<img src="E:\前端の道\Daily_question\http相关\images\http架构.png" alt="http架构" style="zoom:67%;" />

## HTTP/2 中的二进制帧是如何设计的？

### 帧结构

HTTP/2 中传输的帧结构如下图所示:

<img src="E:\前端の道\Daily_question\http相关\images\HTPP2二进制帧.png" alt="HTPP2二进制帧" style="zoom:67%;" />

每个帧分为`帧头`和`帧体`。先是三个字节的帧长度，这个长度表示的是`帧体`的长度。

然后是帧类型，大概可以分为**数据帧**和**控制帧**两种。数据帧用来存放 HTTP 报文，控制帧用来管理`流`的传输。

接下来的一个字节是**帧标志**，里面一共有 8 个标志位，常用的有 **END_HEADERS**表示头数据结束，**END_STREAM**表示单方向数据发送结束。

后 4 个字节是`Stream ID`, 也就是`流标识符`，有了它，接收方就能从乱序的二进制帧中选择出 ID 相同的帧，按顺序组装成请求/响应报文。

### 流的状态变化

从前面可以知道，在 HTTP/2 中，所谓的`流`，其实就是二进制帧的**双向传输的序列**。那么在 HTTP/2 请求和响应的过程中，流的状态是如何变化的呢？

HTTP/2 其实也是借鉴了 TCP 状态变化的思想，根据帧的标志位来实现具体的状态改变。这里我们以一个普通的`请求-响应`过程为例来说明：

<img src="E:\前端の道\Daily_question\http相关\images\HTTP2请求响应.png" alt="HTTP2请求响应" style="zoom:67%;" />

最开始两者都是空闲状态，当客户端发送`Headers帧`后，开始分配`Stream ID`, 此时客户端的`流`打开, 服务端接收之后服务端的`流`也打开，两端的`流`都打开之后，就可以互相传递数据帧和控制帧了。

当客户端要关闭时，向服务端发送`END_STREAM`帧，进入`半关闭状态`, 这个时候客户端只能接收数据，而不能发送数据。

服务端收到这个`END_STREAM`帧后也进入`半关闭状态`，不过此时服务端的情况是只能发送数据，而不能接收数据。随后服务端也向客户端发送`END_STREAM`帧，表示数据发送完毕，双方进入`关闭状态`。

如果下次要开启新的`流`，流 ID 需要自增，直到上限为止，到达上限后开一个新的 TCP 连接重头开始计数。由于流 ID 字段长度为 4 个字节，最高位又被保留，因此范围是 0 ~ 2的 31 次方，大约 21 亿个。

### 流的特性

刚刚谈到了流的状态变化过程，这里顺便就来总结一下`流`传输的特性:

- 并发性。一个 HTTP/2 连接上可以同时发多个帧，这一点和 HTTP/1 不同。这也是实现**多路**复用的基础。
- 自增性。流 ID 是不可重用的，而是会按顺序递增，达到上限之后又新开 TCP 连接从头开始。
- 双向性。客户端和服务端都可以创建流，互不干扰，双方都可以作为`发送方`或者`接收方`。
- 可设置优先级。可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验。